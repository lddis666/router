{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 4266,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007032348804500703,
      "grad_norm": 0.2648330276850472,
      "learning_rate": 2.107728337236534e-06,
      "loss": 0.7069,
      "step": 10
    },
    {
      "epoch": 0.014064697609001406,
      "grad_norm": 0.2617615861661097,
      "learning_rate": 4.4496487119437945e-06,
      "loss": 0.6967,
      "step": 20
    },
    {
      "epoch": 0.02109704641350211,
      "grad_norm": 0.2975371776301315,
      "learning_rate": 6.791569086651055e-06,
      "loss": 0.7403,
      "step": 30
    },
    {
      "epoch": 0.02812939521800281,
      "grad_norm": 0.2760050099448197,
      "learning_rate": 9.133489461358314e-06,
      "loss": 0.6661,
      "step": 40
    },
    {
      "epoch": 0.035161744022503515,
      "grad_norm": 0.3144223013962097,
      "learning_rate": 1.1475409836065575e-05,
      "loss": 0.6799,
      "step": 50
    },
    {
      "epoch": 0.04219409282700422,
      "grad_norm": 0.28061174256575094,
      "learning_rate": 1.3817330210772834e-05,
      "loss": 0.6179,
      "step": 60
    },
    {
      "epoch": 0.04922644163150492,
      "grad_norm": 0.30186891155076684,
      "learning_rate": 1.6159250585480096e-05,
      "loss": 0.5895,
      "step": 70
    },
    {
      "epoch": 0.05625879043600562,
      "grad_norm": 0.3005984497887028,
      "learning_rate": 1.8501170960187357e-05,
      "loss": 0.5685,
      "step": 80
    },
    {
      "epoch": 0.06329113924050633,
      "grad_norm": 0.3326234927462628,
      "learning_rate": 2.0843091334894614e-05,
      "loss": 0.5105,
      "step": 90
    },
    {
      "epoch": 0.07032348804500703,
      "grad_norm": 0.32830740056243396,
      "learning_rate": 2.3185011709601874e-05,
      "loss": 0.4882,
      "step": 100
    },
    {
      "epoch": 0.07735583684950774,
      "grad_norm": 0.3397548559180245,
      "learning_rate": 2.5526932084309135e-05,
      "loss": 0.4828,
      "step": 110
    },
    {
      "epoch": 0.08438818565400844,
      "grad_norm": 0.38473972196448397,
      "learning_rate": 2.7868852459016392e-05,
      "loss": 0.4644,
      "step": 120
    },
    {
      "epoch": 0.09142053445850915,
      "grad_norm": 0.3667409375699598,
      "learning_rate": 3.0210772833723656e-05,
      "loss": 0.4516,
      "step": 130
    },
    {
      "epoch": 0.09845288326300984,
      "grad_norm": 0.46930700068824077,
      "learning_rate": 3.2552693208430914e-05,
      "loss": 0.4457,
      "step": 140
    },
    {
      "epoch": 0.10548523206751055,
      "grad_norm": 0.5106753096529533,
      "learning_rate": 3.489461358313818e-05,
      "loss": 0.4431,
      "step": 150
    },
    {
      "epoch": 0.11251758087201125,
      "grad_norm": 0.44348913612858154,
      "learning_rate": 3.7236533957845435e-05,
      "loss": 0.4222,
      "step": 160
    },
    {
      "epoch": 0.11954992967651196,
      "grad_norm": 0.526130058429,
      "learning_rate": 3.957845433255269e-05,
      "loss": 0.4248,
      "step": 170
    },
    {
      "epoch": 0.12658227848101267,
      "grad_norm": 0.5026713378356873,
      "learning_rate": 4.1920374707259956e-05,
      "loss": 0.4085,
      "step": 180
    },
    {
      "epoch": 0.13361462728551335,
      "grad_norm": 0.4836143691753361,
      "learning_rate": 4.426229508196721e-05,
      "loss": 0.4019,
      "step": 190
    },
    {
      "epoch": 0.14064697609001406,
      "grad_norm": 0.5770980207878825,
      "learning_rate": 4.660421545667448e-05,
      "loss": 0.3891,
      "step": 200
    },
    {
      "epoch": 0.14767932489451477,
      "grad_norm": 0.5377450488372393,
      "learning_rate": 4.8946135831381735e-05,
      "loss": 0.368,
      "step": 210
    },
    {
      "epoch": 0.15471167369901548,
      "grad_norm": 0.6187112243154207,
      "learning_rate": 5.1288056206089e-05,
      "loss": 0.3681,
      "step": 220
    },
    {
      "epoch": 0.1617440225035162,
      "grad_norm": 0.6139381823226548,
      "learning_rate": 5.362997658079626e-05,
      "loss": 0.3742,
      "step": 230
    },
    {
      "epoch": 0.16877637130801687,
      "grad_norm": 0.47436102473932684,
      "learning_rate": 5.597189695550351e-05,
      "loss": 0.3768,
      "step": 240
    },
    {
      "epoch": 0.17580872011251758,
      "grad_norm": 0.5432108069835299,
      "learning_rate": 5.831381733021078e-05,
      "loss": 0.3813,
      "step": 250
    },
    {
      "epoch": 0.1828410689170183,
      "grad_norm": 0.5849735287265574,
      "learning_rate": 6.0655737704918034e-05,
      "loss": 0.3565,
      "step": 260
    },
    {
      "epoch": 0.189873417721519,
      "grad_norm": 0.5846426139218783,
      "learning_rate": 6.29976580796253e-05,
      "loss": 0.3711,
      "step": 270
    },
    {
      "epoch": 0.19690576652601968,
      "grad_norm": 0.5483798910494783,
      "learning_rate": 6.533957845433255e-05,
      "loss": 0.3697,
      "step": 280
    },
    {
      "epoch": 0.2039381153305204,
      "grad_norm": 0.5992147650770329,
      "learning_rate": 6.768149882903982e-05,
      "loss": 0.3522,
      "step": 290
    },
    {
      "epoch": 0.2109704641350211,
      "grad_norm": 0.6392960400445232,
      "learning_rate": 7.002341920374708e-05,
      "loss": 0.3591,
      "step": 300
    },
    {
      "epoch": 0.2180028129395218,
      "grad_norm": 0.5771624341684114,
      "learning_rate": 7.236533957845433e-05,
      "loss": 0.3482,
      "step": 310
    },
    {
      "epoch": 0.2250351617440225,
      "grad_norm": 0.631763501284558,
      "learning_rate": 7.47072599531616e-05,
      "loss": 0.3651,
      "step": 320
    },
    {
      "epoch": 0.2320675105485232,
      "grad_norm": 0.5078004267489407,
      "learning_rate": 7.704918032786885e-05,
      "loss": 0.3545,
      "step": 330
    },
    {
      "epoch": 0.2390998593530239,
      "grad_norm": 0.5374908488961394,
      "learning_rate": 7.939110070257612e-05,
      "loss": 0.3429,
      "step": 340
    },
    {
      "epoch": 0.24613220815752462,
      "grad_norm": 0.6090444523305992,
      "learning_rate": 8.173302107728338e-05,
      "loss": 0.321,
      "step": 350
    },
    {
      "epoch": 0.25316455696202533,
      "grad_norm": 0.7177121227735812,
      "learning_rate": 8.407494145199065e-05,
      "loss": 0.3483,
      "step": 360
    },
    {
      "epoch": 0.26019690576652604,
      "grad_norm": 0.6484006411538656,
      "learning_rate": 8.641686182669789e-05,
      "loss": 0.3309,
      "step": 370
    },
    {
      "epoch": 0.2672292545710267,
      "grad_norm": 0.6226736060372281,
      "learning_rate": 8.875878220140515e-05,
      "loss": 0.3424,
      "step": 380
    },
    {
      "epoch": 0.2742616033755274,
      "grad_norm": 0.5113284309375047,
      "learning_rate": 9.110070257611242e-05,
      "loss": 0.3191,
      "step": 390
    },
    {
      "epoch": 0.2812939521800281,
      "grad_norm": 0.5555819196917597,
      "learning_rate": 9.344262295081968e-05,
      "loss": 0.3385,
      "step": 400
    },
    {
      "epoch": 0.2883263009845288,
      "grad_norm": 0.5620208324991934,
      "learning_rate": 9.578454332552693e-05,
      "loss": 0.326,
      "step": 410
    },
    {
      "epoch": 0.29535864978902954,
      "grad_norm": 0.6007873901805263,
      "learning_rate": 9.812646370023419e-05,
      "loss": 0.3283,
      "step": 420
    },
    {
      "epoch": 0.30239099859353025,
      "grad_norm": 0.6823059407361048,
      "learning_rate": 9.999993303260211e-05,
      "loss": 0.3159,
      "step": 430
    },
    {
      "epoch": 0.30942334739803096,
      "grad_norm": 0.6464658829933875,
      "learning_rate": 9.999758919251108e-05,
      "loss": 0.3037,
      "step": 440
    },
    {
      "epoch": 0.31645569620253167,
      "grad_norm": 0.6344586918093046,
      "learning_rate": 9.99918971619083e-05,
      "loss": 0.3176,
      "step": 450
    },
    {
      "epoch": 0.3234880450070324,
      "grad_norm": 0.562226804368596,
      "learning_rate": 9.99828573219722e-05,
      "loss": 0.32,
      "step": 460
    },
    {
      "epoch": 0.33052039381153303,
      "grad_norm": 0.5465221943299253,
      "learning_rate": 9.997047027807407e-05,
      "loss": 0.3238,
      "step": 470
    },
    {
      "epoch": 0.33755274261603374,
      "grad_norm": 0.4755583473394383,
      "learning_rate": 9.99547368597376e-05,
      "loss": 0.3161,
      "step": 480
    },
    {
      "epoch": 0.34458509142053445,
      "grad_norm": 0.5909191191672356,
      "learning_rate": 9.993565812058322e-05,
      "loss": 0.3015,
      "step": 490
    },
    {
      "epoch": 0.35161744022503516,
      "grad_norm": 0.6050323617675167,
      "learning_rate": 9.991323533825757e-05,
      "loss": 0.3296,
      "step": 500
    },
    {
      "epoch": 0.35864978902953587,
      "grad_norm": 0.5780354232343805,
      "learning_rate": 9.988747001434804e-05,
      "loss": 0.3147,
      "step": 510
    },
    {
      "epoch": 0.3656821378340366,
      "grad_norm": 0.6529603151151201,
      "learning_rate": 9.985836387428206e-05,
      "loss": 0.305,
      "step": 520
    },
    {
      "epoch": 0.3727144866385373,
      "grad_norm": 0.5581936717191015,
      "learning_rate": 9.982591886721165e-05,
      "loss": 0.299,
      "step": 530
    },
    {
      "epoch": 0.379746835443038,
      "grad_norm": 0.5062210113036076,
      "learning_rate": 9.979013716588286e-05,
      "loss": 0.3044,
      "step": 540
    },
    {
      "epoch": 0.38677918424753865,
      "grad_norm": 0.529080990218786,
      "learning_rate": 9.975102116649031e-05,
      "loss": 0.3104,
      "step": 550
    },
    {
      "epoch": 0.39381153305203936,
      "grad_norm": 0.4998842243774188,
      "learning_rate": 9.970857348851666e-05,
      "loss": 0.3147,
      "step": 560
    },
    {
      "epoch": 0.4008438818565401,
      "grad_norm": 0.6063877709384942,
      "learning_rate": 9.966279697455719e-05,
      "loss": 0.2828,
      "step": 570
    },
    {
      "epoch": 0.4078762306610408,
      "grad_norm": 0.6204859492162197,
      "learning_rate": 9.961369469012951e-05,
      "loss": 0.3204,
      "step": 580
    },
    {
      "epoch": 0.4149085794655415,
      "grad_norm": 0.6021888012485744,
      "learning_rate": 9.956126992346824e-05,
      "loss": 0.2883,
      "step": 590
    },
    {
      "epoch": 0.4219409282700422,
      "grad_norm": 0.5405780430123073,
      "learning_rate": 9.950552618530478e-05,
      "loss": 0.2895,
      "step": 600
    },
    {
      "epoch": 0.4289732770745429,
      "grad_norm": 0.5795549666959964,
      "learning_rate": 9.94464672086322e-05,
      "loss": 0.2829,
      "step": 610
    },
    {
      "epoch": 0.4360056258790436,
      "grad_norm": 0.43291997778199415,
      "learning_rate": 9.938409694845534e-05,
      "loss": 0.2859,
      "step": 620
    },
    {
      "epoch": 0.4430379746835443,
      "grad_norm": 0.5592958472466509,
      "learning_rate": 9.931841958152581e-05,
      "loss": 0.3028,
      "step": 630
    },
    {
      "epoch": 0.450070323488045,
      "grad_norm": 0.5736530339912509,
      "learning_rate": 9.924943950606244e-05,
      "loss": 0.2876,
      "step": 640
    },
    {
      "epoch": 0.4571026722925457,
      "grad_norm": 0.5324547778321399,
      "learning_rate": 9.917716134145664e-05,
      "loss": 0.3024,
      "step": 650
    },
    {
      "epoch": 0.4641350210970464,
      "grad_norm": 0.6478896816433493,
      "learning_rate": 9.910158992796307e-05,
      "loss": 0.3099,
      "step": 660
    },
    {
      "epoch": 0.4711673699015471,
      "grad_norm": 0.506003898648712,
      "learning_rate": 9.902273032637556e-05,
      "loss": 0.2891,
      "step": 670
    },
    {
      "epoch": 0.4781997187060478,
      "grad_norm": 0.5225319406951419,
      "learning_rate": 9.894058781768813e-05,
      "loss": 0.3003,
      "step": 680
    },
    {
      "epoch": 0.48523206751054854,
      "grad_norm": 0.5499903573525488,
      "learning_rate": 9.885516790274137e-05,
      "loss": 0.2907,
      "step": 690
    },
    {
      "epoch": 0.49226441631504925,
      "grad_norm": 0.5508134897318495,
      "learning_rate": 9.876647630185403e-05,
      "loss": 0.2779,
      "step": 700
    },
    {
      "epoch": 0.49929676511954996,
      "grad_norm": 0.5865218236802318,
      "learning_rate": 9.867451895444009e-05,
      "loss": 0.3001,
      "step": 710
    },
    {
      "epoch": 0.5063291139240507,
      "grad_norm": 0.5182051697973367,
      "learning_rate": 9.857930201861077e-05,
      "loss": 0.2695,
      "step": 720
    },
    {
      "epoch": 0.5133614627285513,
      "grad_norm": 0.5304982490925756,
      "learning_rate": 9.848083187076236e-05,
      "loss": 0.2788,
      "step": 730
    },
    {
      "epoch": 0.5203938115330521,
      "grad_norm": 0.48928497716466257,
      "learning_rate": 9.83791151051491e-05,
      "loss": 0.2692,
      "step": 740
    },
    {
      "epoch": 0.5274261603375527,
      "grad_norm": 0.46146963750233655,
      "learning_rate": 9.827415853344162e-05,
      "loss": 0.2966,
      "step": 750
    },
    {
      "epoch": 0.5344585091420534,
      "grad_norm": 0.6042241230131947,
      "learning_rate": 9.816596918427074e-05,
      "loss": 0.2919,
      "step": 760
    },
    {
      "epoch": 0.5414908579465542,
      "grad_norm": 0.5732213994586607,
      "learning_rate": 9.80545543027569e-05,
      "loss": 0.2837,
      "step": 770
    },
    {
      "epoch": 0.5485232067510548,
      "grad_norm": 0.5347770756467395,
      "learning_rate": 9.793992135002476e-05,
      "loss": 0.291,
      "step": 780
    },
    {
      "epoch": 0.5555555555555556,
      "grad_norm": 0.6171398552941041,
      "learning_rate": 9.782207800270378e-05,
      "loss": 0.2846,
      "step": 790
    },
    {
      "epoch": 0.5625879043600562,
      "grad_norm": 0.5153277530441256,
      "learning_rate": 9.770103215241402e-05,
      "loss": 0.2804,
      "step": 800
    },
    {
      "epoch": 0.569620253164557,
      "grad_norm": 0.5798751890473484,
      "learning_rate": 9.757679190523766e-05,
      "loss": 0.2862,
      "step": 810
    },
    {
      "epoch": 0.5766526019690577,
      "grad_norm": 0.5903952993856519,
      "learning_rate": 9.74493655811762e-05,
      "loss": 0.2617,
      "step": 820
    },
    {
      "epoch": 0.5836849507735584,
      "grad_norm": 0.593062946520236,
      "learning_rate": 9.731876171359326e-05,
      "loss": 0.2824,
      "step": 830
    },
    {
      "epoch": 0.5907172995780591,
      "grad_norm": 0.5024618101176199,
      "learning_rate": 9.718498904864317e-05,
      "loss": 0.3051,
      "step": 840
    },
    {
      "epoch": 0.5977496483825597,
      "grad_norm": 0.502681260666262,
      "learning_rate": 9.704805654468519e-05,
      "loss": 0.2816,
      "step": 850
    },
    {
      "epoch": 0.6047819971870605,
      "grad_norm": 0.5197489691839233,
      "learning_rate": 9.69079733716837e-05,
      "loss": 0.2793,
      "step": 860
    },
    {
      "epoch": 0.6118143459915611,
      "grad_norm": 0.5018000054665535,
      "learning_rate": 9.676474891059402e-05,
      "loss": 0.2564,
      "step": 870
    },
    {
      "epoch": 0.6188466947960619,
      "grad_norm": 0.5412532259033352,
      "learning_rate": 9.661839275273421e-05,
      "loss": 0.2852,
      "step": 880
    },
    {
      "epoch": 0.6258790436005626,
      "grad_norm": 0.6218272430217923,
      "learning_rate": 9.646891469914286e-05,
      "loss": 0.2719,
      "step": 890
    },
    {
      "epoch": 0.6329113924050633,
      "grad_norm": 0.5166234661473349,
      "learning_rate": 9.63163247599226e-05,
      "loss": 0.2737,
      "step": 900
    },
    {
      "epoch": 0.639943741209564,
      "grad_norm": 0.6466400928063447,
      "learning_rate": 9.616063315356988e-05,
      "loss": 0.2683,
      "step": 910
    },
    {
      "epoch": 0.6469760900140648,
      "grad_norm": 0.5172875305954368,
      "learning_rate": 9.600185030629062e-05,
      "loss": 0.2614,
      "step": 920
    },
    {
      "epoch": 0.6540084388185654,
      "grad_norm": 0.5607625987388359,
      "learning_rate": 9.58399868513019e-05,
      "loss": 0.2634,
      "step": 930
    },
    {
      "epoch": 0.6610407876230661,
      "grad_norm": 0.49910790585975745,
      "learning_rate": 9.567505362812013e-05,
      "loss": 0.2809,
      "step": 940
    },
    {
      "epoch": 0.6680731364275668,
      "grad_norm": 0.5283329145273313,
      "learning_rate": 9.550706168183483e-05,
      "loss": 0.2635,
      "step": 950
    },
    {
      "epoch": 0.6751054852320675,
      "grad_norm": 0.5809684358591805,
      "learning_rate": 9.533602226236931e-05,
      "loss": 0.2652,
      "step": 960
    },
    {
      "epoch": 0.6821378340365682,
      "grad_norm": 0.470437635745331,
      "learning_rate": 9.516194682372701e-05,
      "loss": 0.2463,
      "step": 970
    },
    {
      "epoch": 0.6891701828410689,
      "grad_norm": 0.594087881813457,
      "learning_rate": 9.49848470232247e-05,
      "loss": 0.2743,
      "step": 980
    },
    {
      "epoch": 0.6962025316455697,
      "grad_norm": 0.4954445971103185,
      "learning_rate": 9.480473472071158e-05,
      "loss": 0.2643,
      "step": 990
    },
    {
      "epoch": 0.7032348804500703,
      "grad_norm": 0.5175963781562659,
      "learning_rate": 9.462162197777533e-05,
      "loss": 0.3026,
      "step": 1000
    },
    {
      "epoch": 0.710267229254571,
      "grad_norm": 0.45257335803836124,
      "learning_rate": 9.443552105693414e-05,
      "loss": 0.2785,
      "step": 1010
    },
    {
      "epoch": 0.7172995780590717,
      "grad_norm": 0.4589997213321089,
      "learning_rate": 9.424644442081565e-05,
      "loss": 0.2613,
      "step": 1020
    },
    {
      "epoch": 0.7243319268635724,
      "grad_norm": 0.4619823070384093,
      "learning_rate": 9.405440473132234e-05,
      "loss": 0.2543,
      "step": 1030
    },
    {
      "epoch": 0.7313642756680732,
      "grad_norm": 0.5801890026547218,
      "learning_rate": 9.385941484878366e-05,
      "loss": 0.2698,
      "step": 1040
    },
    {
      "epoch": 0.7383966244725738,
      "grad_norm": 0.4843894871991488,
      "learning_rate": 9.366148783109465e-05,
      "loss": 0.2615,
      "step": 1050
    },
    {
      "epoch": 0.7454289732770746,
      "grad_norm": 0.49890147993375594,
      "learning_rate": 9.346063693284166e-05,
      "loss": 0.2669,
      "step": 1060
    },
    {
      "epoch": 0.7524613220815752,
      "grad_norm": 0.5223213015114142,
      "learning_rate": 9.325687560441467e-05,
      "loss": 0.2579,
      "step": 1070
    },
    {
      "epoch": 0.759493670886076,
      "grad_norm": 0.5012509533763462,
      "learning_rate": 9.305021749110654e-05,
      "loss": 0.2854,
      "step": 1080
    },
    {
      "epoch": 0.7665260196905767,
      "grad_norm": 0.5500724002362981,
      "learning_rate": 9.28406764321992e-05,
      "loss": 0.2653,
      "step": 1090
    },
    {
      "epoch": 0.7735583684950773,
      "grad_norm": 0.5054198950435023,
      "learning_rate": 9.262826646003695e-05,
      "loss": 0.2585,
      "step": 1100
    },
    {
      "epoch": 0.7805907172995781,
      "grad_norm": 0.60902613023068,
      "learning_rate": 9.241300179908672e-05,
      "loss": 0.2726,
      "step": 1110
    },
    {
      "epoch": 0.7876230661040787,
      "grad_norm": 0.42891927017214343,
      "learning_rate": 9.219489686498548e-05,
      "loss": 0.2615,
      "step": 1120
    },
    {
      "epoch": 0.7946554149085795,
      "grad_norm": 0.5100812526456889,
      "learning_rate": 9.197396626357487e-05,
      "loss": 0.2664,
      "step": 1130
    },
    {
      "epoch": 0.8016877637130801,
      "grad_norm": 0.6267058186046136,
      "learning_rate": 9.175022478992313e-05,
      "loss": 0.2491,
      "step": 1140
    },
    {
      "epoch": 0.8087201125175809,
      "grad_norm": 0.5431972167155199,
      "learning_rate": 9.152368742733429e-05,
      "loss": 0.257,
      "step": 1150
    },
    {
      "epoch": 0.8157524613220816,
      "grad_norm": 0.486856108716701,
      "learning_rate": 9.129436934634477e-05,
      "loss": 0.2564,
      "step": 1160
    },
    {
      "epoch": 0.8227848101265823,
      "grad_norm": 0.6649351260240417,
      "learning_rate": 9.106228590370745e-05,
      "loss": 0.2708,
      "step": 1170
    },
    {
      "epoch": 0.829817158931083,
      "grad_norm": 0.4328417520580085,
      "learning_rate": 9.082745264136335e-05,
      "loss": 0.2503,
      "step": 1180
    },
    {
      "epoch": 0.8368495077355836,
      "grad_norm": 0.5415428413525705,
      "learning_rate": 9.058988528540069e-05,
      "loss": 0.2876,
      "step": 1190
    },
    {
      "epoch": 0.8438818565400844,
      "grad_norm": 0.47996623579085884,
      "learning_rate": 9.034959974500195e-05,
      "loss": 0.2321,
      "step": 1200
    },
    {
      "epoch": 0.8509142053445851,
      "grad_norm": 0.4992423264897066,
      "learning_rate": 9.010661211137827e-05,
      "loss": 0.2546,
      "step": 1210
    },
    {
      "epoch": 0.8579465541490858,
      "grad_norm": 0.5083130520024929,
      "learning_rate": 8.986093865669206e-05,
      "loss": 0.2726,
      "step": 1220
    },
    {
      "epoch": 0.8649789029535865,
      "grad_norm": 0.5383978197283706,
      "learning_rate": 8.961259583296712e-05,
      "loss": 0.258,
      "step": 1230
    },
    {
      "epoch": 0.8720112517580872,
      "grad_norm": 0.5457236924677551,
      "learning_rate": 8.936160027098708e-05,
      "loss": 0.2636,
      "step": 1240
    },
    {
      "epoch": 0.8790436005625879,
      "grad_norm": 0.4615352724010986,
      "learning_rate": 8.910796877918156e-05,
      "loss": 0.2616,
      "step": 1250
    },
    {
      "epoch": 0.8860759493670886,
      "grad_norm": 0.4675808430893925,
      "learning_rate": 8.885171834250059e-05,
      "loss": 0.2491,
      "step": 1260
    },
    {
      "epoch": 0.8931082981715893,
      "grad_norm": 0.5180595784690492,
      "learning_rate": 8.859286612127718e-05,
      "loss": 0.2521,
      "step": 1270
    },
    {
      "epoch": 0.90014064697609,
      "grad_norm": 0.4995869223642671,
      "learning_rate": 8.833142945007818e-05,
      "loss": 0.2682,
      "step": 1280
    },
    {
      "epoch": 0.9071729957805907,
      "grad_norm": 0.46161830194639175,
      "learning_rate": 8.806742583654335e-05,
      "loss": 0.2683,
      "step": 1290
    },
    {
      "epoch": 0.9142053445850914,
      "grad_norm": 0.4717449689484346,
      "learning_rate": 8.780087296021302e-05,
      "loss": 0.243,
      "step": 1300
    },
    {
      "epoch": 0.9212376933895922,
      "grad_norm": 0.5333549091719888,
      "learning_rate": 8.753178867134409e-05,
      "loss": 0.2412,
      "step": 1310
    },
    {
      "epoch": 0.9282700421940928,
      "grad_norm": 0.5441369679464569,
      "learning_rate": 8.726019098971467e-05,
      "loss": 0.2345,
      "step": 1320
    },
    {
      "epoch": 0.9353023909985936,
      "grad_norm": 0.5010971054174981,
      "learning_rate": 8.698609810341733e-05,
      "loss": 0.256,
      "step": 1330
    },
    {
      "epoch": 0.9423347398030942,
      "grad_norm": 0.5711289218994479,
      "learning_rate": 8.67095283676411e-05,
      "loss": 0.2477,
      "step": 1340
    },
    {
      "epoch": 0.9493670886075949,
      "grad_norm": 0.4787777551284936,
      "learning_rate": 8.643050030344231e-05,
      "loss": 0.2381,
      "step": 1350
    },
    {
      "epoch": 0.9563994374120957,
      "grad_norm": 0.4831101779282772,
      "learning_rate": 8.614903259650424e-05,
      "loss": 0.2387,
      "step": 1360
    },
    {
      "epoch": 0.9634317862165963,
      "grad_norm": 0.5021670045549506,
      "learning_rate": 8.586514409588584e-05,
      "loss": 0.2528,
      "step": 1370
    },
    {
      "epoch": 0.9704641350210971,
      "grad_norm": 0.5078079294783339,
      "learning_rate": 8.557885381275943e-05,
      "loss": 0.2426,
      "step": 1380
    },
    {
      "epoch": 0.9774964838255977,
      "grad_norm": 0.5434573102979324,
      "learning_rate": 8.529018091913763e-05,
      "loss": 0.2341,
      "step": 1390
    },
    {
      "epoch": 0.9845288326300985,
      "grad_norm": 0.5018311840559275,
      "learning_rate": 8.499914474658938e-05,
      "loss": 0.2358,
      "step": 1400
    },
    {
      "epoch": 0.9915611814345991,
      "grad_norm": 0.48787722177052345,
      "learning_rate": 8.470576478494542e-05,
      "loss": 0.2675,
      "step": 1410
    },
    {
      "epoch": 0.9985935302390999,
      "grad_norm": 0.573182364591835,
      "learning_rate": 8.441006068099318e-05,
      "loss": 0.2852,
      "step": 1420
    },
    {
      "epoch": 1.0056258790436006,
      "grad_norm": 0.5148601619556612,
      "learning_rate": 8.411205223716088e-05,
      "loss": 0.2391,
      "step": 1430
    },
    {
      "epoch": 1.0126582278481013,
      "grad_norm": 0.5222959535799686,
      "learning_rate": 8.38117594101917e-05,
      "loss": 0.2265,
      "step": 1440
    },
    {
      "epoch": 1.0196905766526019,
      "grad_norm": 0.502302062996194,
      "learning_rate": 8.35092023098071e-05,
      "loss": 0.2373,
      "step": 1450
    },
    {
      "epoch": 1.0267229254571026,
      "grad_norm": 0.540997556611996,
      "learning_rate": 8.320440119736028e-05,
      "loss": 0.2231,
      "step": 1460
    },
    {
      "epoch": 1.0337552742616034,
      "grad_norm": 0.5192075065819776,
      "learning_rate": 8.289737648447924e-05,
      "loss": 0.2271,
      "step": 1470
    },
    {
      "epoch": 1.0407876230661042,
      "grad_norm": 0.5928213879090107,
      "learning_rate": 8.258814873169997e-05,
      "loss": 0.222,
      "step": 1480
    },
    {
      "epoch": 1.0478199718706047,
      "grad_norm": 0.46225742427700967,
      "learning_rate": 8.227673864708947e-05,
      "loss": 0.2304,
      "step": 1490
    },
    {
      "epoch": 1.0548523206751055,
      "grad_norm": 0.4398556387445432,
      "learning_rate": 8.196316708485907e-05,
      "loss": 0.236,
      "step": 1500
    },
    {
      "epoch": 1.0618846694796062,
      "grad_norm": 0.6025231733008103,
      "learning_rate": 8.164745504396785e-05,
      "loss": 0.2333,
      "step": 1510
    },
    {
      "epoch": 1.0689170182841068,
      "grad_norm": 0.5147625423171936,
      "learning_rate": 8.13296236667164e-05,
      "loss": 0.2261,
      "step": 1520
    },
    {
      "epoch": 1.0759493670886076,
      "grad_norm": 0.5691375793808472,
      "learning_rate": 8.100969423733096e-05,
      "loss": 0.2229,
      "step": 1530
    },
    {
      "epoch": 1.0829817158931083,
      "grad_norm": 0.5315578135115713,
      "learning_rate": 8.068768818053821e-05,
      "loss": 0.2377,
      "step": 1540
    },
    {
      "epoch": 1.090014064697609,
      "grad_norm": 0.4980639448755952,
      "learning_rate": 8.036362706013033e-05,
      "loss": 0.2207,
      "step": 1550
    },
    {
      "epoch": 1.0970464135021096,
      "grad_norm": 0.5414393510094091,
      "learning_rate": 8.003753257752104e-05,
      "loss": 0.2151,
      "step": 1560
    },
    {
      "epoch": 1.1040787623066104,
      "grad_norm": 0.6693084376072798,
      "learning_rate": 7.970942657029232e-05,
      "loss": 0.2425,
      "step": 1570
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.46556601050827573,
      "learning_rate": 7.937933101073201e-05,
      "loss": 0.2252,
      "step": 1580
    },
    {
      "epoch": 1.1181434599156117,
      "grad_norm": 0.5280863301537796,
      "learning_rate": 7.904726800436233e-05,
      "loss": 0.2304,
      "step": 1590
    },
    {
      "epoch": 1.1251758087201125,
      "grad_norm": 0.4384490264948934,
      "learning_rate": 7.871325978845964e-05,
      "loss": 0.2215,
      "step": 1600
    },
    {
      "epoch": 1.1322081575246132,
      "grad_norm": 0.6939599067670228,
      "learning_rate": 7.837732873056523e-05,
      "loss": 0.2211,
      "step": 1610
    },
    {
      "epoch": 1.139240506329114,
      "grad_norm": 0.4656022654918418,
      "learning_rate": 7.803949732698735e-05,
      "loss": 0.2153,
      "step": 1620
    },
    {
      "epoch": 1.1462728551336145,
      "grad_norm": 0.5032327750559334,
      "learning_rate": 7.769978820129487e-05,
      "loss": 0.2249,
      "step": 1630
    },
    {
      "epoch": 1.1533052039381153,
      "grad_norm": 0.5580943859532879,
      "learning_rate": 7.735822410280204e-05,
      "loss": 0.2146,
      "step": 1640
    },
    {
      "epoch": 1.160337552742616,
      "grad_norm": 0.5823728410693929,
      "learning_rate": 7.701482790504527e-05,
      "loss": 0.2397,
      "step": 1650
    },
    {
      "epoch": 1.1673699015471168,
      "grad_norm": 0.5188689798422941,
      "learning_rate": 7.666962260425113e-05,
      "loss": 0.2159,
      "step": 1660
    },
    {
      "epoch": 1.1744022503516174,
      "grad_norm": 0.5802643418438412,
      "learning_rate": 7.632263131779655e-05,
      "loss": 0.2105,
      "step": 1670
    },
    {
      "epoch": 1.1814345991561181,
      "grad_norm": 0.5371923705233581,
      "learning_rate": 7.597387728266054e-05,
      "loss": 0.2,
      "step": 1680
    },
    {
      "epoch": 1.188466947960619,
      "grad_norm": 0.5583091529005362,
      "learning_rate": 7.562338385386822e-05,
      "loss": 0.2278,
      "step": 1690
    },
    {
      "epoch": 1.1954992967651195,
      "grad_norm": 0.5486631887742958,
      "learning_rate": 7.527117450292679e-05,
      "loss": 0.2235,
      "step": 1700
    },
    {
      "epoch": 1.2025316455696202,
      "grad_norm": 0.5307479841154017,
      "learning_rate": 7.49172728162536e-05,
      "loss": 0.2194,
      "step": 1710
    },
    {
      "epoch": 1.209563994374121,
      "grad_norm": 0.544154644874811,
      "learning_rate": 7.456170249359679e-05,
      "loss": 0.2202,
      "step": 1720
    },
    {
      "epoch": 1.2165963431786218,
      "grad_norm": 0.5405763275766879,
      "learning_rate": 7.420448734644801e-05,
      "loss": 0.2273,
      "step": 1730
    },
    {
      "epoch": 1.2236286919831223,
      "grad_norm": 0.5161442248849674,
      "learning_rate": 7.384565129644803e-05,
      "loss": 0.2156,
      "step": 1740
    },
    {
      "epoch": 1.230661040787623,
      "grad_norm": 0.4635675558604165,
      "learning_rate": 7.348521837378465e-05,
      "loss": 0.2172,
      "step": 1750
    },
    {
      "epoch": 1.2376933895921238,
      "grad_norm": 0.5392241070245452,
      "learning_rate": 7.312321271558351e-05,
      "loss": 0.2174,
      "step": 1760
    },
    {
      "epoch": 1.2447257383966246,
      "grad_norm": 0.4284829097237841,
      "learning_rate": 7.275965856429167e-05,
      "loss": 0.2265,
      "step": 1770
    },
    {
      "epoch": 1.2517580872011251,
      "grad_norm": 0.6243762747364033,
      "learning_rate": 7.239458026605424e-05,
      "loss": 0.2146,
      "step": 1780
    },
    {
      "epoch": 1.258790436005626,
      "grad_norm": 0.472082498848974,
      "learning_rate": 7.202800226908386e-05,
      "loss": 0.2007,
      "step": 1790
    },
    {
      "epoch": 1.2658227848101267,
      "grad_norm": 0.4980077448417017,
      "learning_rate": 7.165994912202361e-05,
      "loss": 0.2143,
      "step": 1800
    },
    {
      "epoch": 1.2728551336146272,
      "grad_norm": 0.49831319851608263,
      "learning_rate": 7.1290445472303e-05,
      "loss": 0.2104,
      "step": 1810
    },
    {
      "epoch": 1.279887482419128,
      "grad_norm": 0.6104833046873812,
      "learning_rate": 7.091951606448738e-05,
      "loss": 0.2286,
      "step": 1820
    },
    {
      "epoch": 1.2869198312236287,
      "grad_norm": 0.46523603047301604,
      "learning_rate": 7.054718573862096e-05,
      "loss": 0.2217,
      "step": 1830
    },
    {
      "epoch": 1.2939521800281293,
      "grad_norm": 0.6209305671401234,
      "learning_rate": 7.01734794285632e-05,
      "loss": 0.2197,
      "step": 1840
    },
    {
      "epoch": 1.30098452883263,
      "grad_norm": 0.4897142710304009,
      "learning_rate": 6.979842216031919e-05,
      "loss": 0.2305,
      "step": 1850
    },
    {
      "epoch": 1.3080168776371308,
      "grad_norm": 0.46839196385078813,
      "learning_rate": 6.94220390503637e-05,
      "loss": 0.2276,
      "step": 1860
    },
    {
      "epoch": 1.3150492264416316,
      "grad_norm": 0.545960442908202,
      "learning_rate": 6.904435530395919e-05,
      "loss": 0.2284,
      "step": 1870
    },
    {
      "epoch": 1.3220815752461323,
      "grad_norm": 0.5105692442366551,
      "learning_rate": 6.866539621346786e-05,
      "loss": 0.2291,
      "step": 1880
    },
    {
      "epoch": 1.3291139240506329,
      "grad_norm": 0.49140645797461435,
      "learning_rate": 6.828518715665798e-05,
      "loss": 0.2077,
      "step": 1890
    },
    {
      "epoch": 1.3361462728551337,
      "grad_norm": 0.5384046024110306,
      "learning_rate": 6.79037535950043e-05,
      "loss": 0.2329,
      "step": 1900
    },
    {
      "epoch": 1.3431786216596344,
      "grad_norm": 0.49637329646367767,
      "learning_rate": 6.752112107198309e-05,
      "loss": 0.2111,
      "step": 1910
    },
    {
      "epoch": 1.350210970464135,
      "grad_norm": 0.45871780175942,
      "learning_rate": 6.713731521136148e-05,
      "loss": 0.2049,
      "step": 1920
    },
    {
      "epoch": 1.3572433192686357,
      "grad_norm": 0.5022631326907288,
      "learning_rate": 6.675236171548158e-05,
      "loss": 0.2291,
      "step": 1930
    },
    {
      "epoch": 1.3642756680731365,
      "grad_norm": 0.5666070020017466,
      "learning_rate": 6.636628636353917e-05,
      "loss": 0.2164,
      "step": 1940
    },
    {
      "epoch": 1.371308016877637,
      "grad_norm": 0.489204179829548,
      "learning_rate": 6.59791150098575e-05,
      "loss": 0.2183,
      "step": 1950
    },
    {
      "epoch": 1.3783403656821378,
      "grad_norm": 0.5177703768418819,
      "learning_rate": 6.559087358215572e-05,
      "loss": 0.2248,
      "step": 1960
    },
    {
      "epoch": 1.3853727144866386,
      "grad_norm": 0.5291796914187329,
      "learning_rate": 6.520158807981271e-05,
      "loss": 0.239,
      "step": 1970
    },
    {
      "epoch": 1.3924050632911391,
      "grad_norm": 0.48844765321488576,
      "learning_rate": 6.481128457212597e-05,
      "loss": 0.2196,
      "step": 1980
    },
    {
      "epoch": 1.3994374120956399,
      "grad_norm": 0.5131218597161428,
      "learning_rate": 6.441998919656576e-05,
      "loss": 0.2178,
      "step": 1990
    },
    {
      "epoch": 1.4064697609001406,
      "grad_norm": 0.6029984063930501,
      "learning_rate": 6.402772815702478e-05,
      "loss": 0.2174,
      "step": 2000
    },
    {
      "epoch": 1.4135021097046414,
      "grad_norm": 0.4969536957488336,
      "learning_rate": 6.363452772206344e-05,
      "loss": 0.2257,
      "step": 2010
    },
    {
      "epoch": 1.4205344585091422,
      "grad_norm": 0.560844273480563,
      "learning_rate": 6.324041422315064e-05,
      "loss": 0.2049,
      "step": 2020
    },
    {
      "epoch": 1.4275668073136427,
      "grad_norm": 0.4338336029360171,
      "learning_rate": 6.284541405290049e-05,
      "loss": 0.2088,
      "step": 2030
    },
    {
      "epoch": 1.4345991561181435,
      "grad_norm": 0.5438780711086506,
      "learning_rate": 6.244955366330484e-05,
      "loss": 0.2212,
      "step": 2040
    },
    {
      "epoch": 1.4416315049226442,
      "grad_norm": 0.5480341203760704,
      "learning_rate": 6.20528595639619e-05,
      "loss": 0.2237,
      "step": 2050
    },
    {
      "epoch": 1.4486638537271448,
      "grad_norm": 0.5299508397963301,
      "learning_rate": 6.165535832030094e-05,
      "loss": 0.2185,
      "step": 2060
    },
    {
      "epoch": 1.4556962025316456,
      "grad_norm": 0.5108015165164682,
      "learning_rate": 6.125707655180328e-05,
      "loss": 0.2193,
      "step": 2070
    },
    {
      "epoch": 1.4627285513361463,
      "grad_norm": 0.48756434397824766,
      "learning_rate": 6.0858040930219716e-05,
      "loss": 0.2078,
      "step": 2080
    },
    {
      "epoch": 1.4697609001406469,
      "grad_norm": 0.6085370021472952,
      "learning_rate": 6.0458278177784325e-05,
      "loss": 0.2144,
      "step": 2090
    },
    {
      "epoch": 1.4767932489451476,
      "grad_norm": 0.4966720925828994,
      "learning_rate": 6.005781506542498e-05,
      "loss": 0.2152,
      "step": 2100
    },
    {
      "epoch": 1.4838255977496484,
      "grad_norm": 0.4464551761623177,
      "learning_rate": 5.965667841097062e-05,
      "loss": 0.2143,
      "step": 2110
    },
    {
      "epoch": 1.4908579465541492,
      "grad_norm": 0.49017660359607657,
      "learning_rate": 5.9254895077355264e-05,
      "loss": 0.2217,
      "step": 2120
    },
    {
      "epoch": 1.49789029535865,
      "grad_norm": 0.5122950653117824,
      "learning_rate": 5.8852491970819136e-05,
      "loss": 0.221,
      "step": 2130
    },
    {
      "epoch": 1.5049226441631505,
      "grad_norm": 0.48904033322294976,
      "learning_rate": 5.844949603910683e-05,
      "loss": 0.2133,
      "step": 2140
    },
    {
      "epoch": 1.5119549929676512,
      "grad_norm": 0.4818299747503884,
      "learning_rate": 5.804593426966265e-05,
      "loss": 0.2072,
      "step": 2150
    },
    {
      "epoch": 1.518987341772152,
      "grad_norm": 0.4856797077359925,
      "learning_rate": 5.76418336878234e-05,
      "loss": 0.2204,
      "step": 2160
    },
    {
      "epoch": 1.5260196905766525,
      "grad_norm": 0.5524935513886164,
      "learning_rate": 5.723722135500858e-05,
      "loss": 0.2142,
      "step": 2170
    },
    {
      "epoch": 1.5330520393811533,
      "grad_norm": 0.4745256856877759,
      "learning_rate": 5.68321243669081e-05,
      "loss": 0.2245,
      "step": 2180
    },
    {
      "epoch": 1.540084388185654,
      "grad_norm": 0.5505511710551111,
      "learning_rate": 5.642656985166782e-05,
      "loss": 0.2198,
      "step": 2190
    },
    {
      "epoch": 1.5471167369901546,
      "grad_norm": 0.5082924775067469,
      "learning_rate": 5.602058496807281e-05,
      "loss": 0.2284,
      "step": 2200
    },
    {
      "epoch": 1.5541490857946554,
      "grad_norm": 0.42577926320052734,
      "learning_rate": 5.561419690372869e-05,
      "loss": 0.209,
      "step": 2210
    },
    {
      "epoch": 1.5611814345991561,
      "grad_norm": 0.4805998726182696,
      "learning_rate": 5.520743287324083e-05,
      "loss": 0.2314,
      "step": 2220
    },
    {
      "epoch": 1.5682137834036567,
      "grad_norm": 0.5263996528771707,
      "learning_rate": 5.4800320116392e-05,
      "loss": 0.2221,
      "step": 2230
    },
    {
      "epoch": 1.5752461322081577,
      "grad_norm": 0.4319314368909356,
      "learning_rate": 5.43928858963181e-05,
      "loss": 0.2098,
      "step": 2240
    },
    {
      "epoch": 1.5822784810126582,
      "grad_norm": 0.4988013309313036,
      "learning_rate": 5.3985157497682504e-05,
      "loss": 0.2147,
      "step": 2250
    },
    {
      "epoch": 1.5893108298171588,
      "grad_norm": 0.48882705252148856,
      "learning_rate": 5.357716222484882e-05,
      "loss": 0.2071,
      "step": 2260
    },
    {
      "epoch": 1.5963431786216598,
      "grad_norm": 0.5785254165875471,
      "learning_rate": 5.316892740005246e-05,
      "loss": 0.2102,
      "step": 2270
    },
    {
      "epoch": 1.6033755274261603,
      "grad_norm": 0.5057617383888877,
      "learning_rate": 5.276048036157092e-05,
      "loss": 0.2101,
      "step": 2280
    },
    {
      "epoch": 1.610407876230661,
      "grad_norm": 0.5579098868047464,
      "learning_rate": 5.2351848461892996e-05,
      "loss": 0.2191,
      "step": 2290
    },
    {
      "epoch": 1.6174402250351618,
      "grad_norm": 0.4924582310802958,
      "learning_rate": 5.1943059065887076e-05,
      "loss": 0.1966,
      "step": 2300
    },
    {
      "epoch": 1.6244725738396624,
      "grad_norm": 0.5327974112886142,
      "learning_rate": 5.153413954896867e-05,
      "loss": 0.219,
      "step": 2310
    },
    {
      "epoch": 1.6315049226441631,
      "grad_norm": 0.4536541980343996,
      "learning_rate": 5.1125117295267075e-05,
      "loss": 0.2212,
      "step": 2320
    },
    {
      "epoch": 1.638537271448664,
      "grad_norm": 0.48770973721805866,
      "learning_rate": 5.071601969579153e-05,
      "loss": 0.2189,
      "step": 2330
    },
    {
      "epoch": 1.6455696202531644,
      "grad_norm": 0.5306905735406288,
      "learning_rate": 5.0306874146597015e-05,
      "loss": 0.214,
      "step": 2340
    },
    {
      "epoch": 1.6526019690576652,
      "grad_norm": 0.49322028056300843,
      "learning_rate": 4.989770804694951e-05,
      "loss": 0.2099,
      "step": 2350
    },
    {
      "epoch": 1.659634317862166,
      "grad_norm": 0.5696565385286977,
      "learning_rate": 4.948854879749122e-05,
      "loss": 0.227,
      "step": 2360
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.5160708747822194,
      "learning_rate": 4.907942379840564e-05,
      "loss": 0.2111,
      "step": 2370
    },
    {
      "epoch": 1.6736990154711675,
      "grad_norm": 0.5974244959596676,
      "learning_rate": 4.867036044758256e-05,
      "loss": 0.2154,
      "step": 2380
    },
    {
      "epoch": 1.680731364275668,
      "grad_norm": 0.4991338034134833,
      "learning_rate": 4.826138613878341e-05,
      "loss": 0.1939,
      "step": 2390
    },
    {
      "epoch": 1.6877637130801688,
      "grad_norm": 0.5906188495415268,
      "learning_rate": 4.7852528259806736e-05,
      "loss": 0.2115,
      "step": 2400
    },
    {
      "epoch": 1.6947960618846696,
      "grad_norm": 0.5379852014559902,
      "learning_rate": 4.744381419065411e-05,
      "loss": 0.2065,
      "step": 2410
    },
    {
      "epoch": 1.7018284106891701,
      "grad_norm": 0.5506903344656301,
      "learning_rate": 4.703527130169661e-05,
      "loss": 0.2071,
      "step": 2420
    },
    {
      "epoch": 1.7088607594936709,
      "grad_norm": 0.5227147106495883,
      "learning_rate": 4.662692695184184e-05,
      "loss": 0.2137,
      "step": 2430
    },
    {
      "epoch": 1.7158931082981717,
      "grad_norm": 0.47022437979488546,
      "learning_rate": 4.6218808486701866e-05,
      "loss": 0.2073,
      "step": 2440
    },
    {
      "epoch": 1.7229254571026722,
      "grad_norm": 0.5296051888102691,
      "learning_rate": 4.581094323676193e-05,
      "loss": 0.2183,
      "step": 2450
    },
    {
      "epoch": 1.729957805907173,
      "grad_norm": 0.5910586542781809,
      "learning_rate": 4.540335851555014e-05,
      "loss": 0.2151,
      "step": 2460
    },
    {
      "epoch": 1.7369901547116737,
      "grad_norm": 0.633283340906139,
      "learning_rate": 4.4996081617808514e-05,
      "loss": 0.2137,
      "step": 2470
    },
    {
      "epoch": 1.7440225035161743,
      "grad_norm": 0.5349235317812302,
      "learning_rate": 4.458913981766499e-05,
      "loss": 0.2218,
      "step": 2480
    },
    {
      "epoch": 1.7510548523206753,
      "grad_norm": 0.5918709825744009,
      "learning_rate": 4.4182560366807e-05,
      "loss": 0.205,
      "step": 2490
    },
    {
      "epoch": 1.7580872011251758,
      "grad_norm": 0.5348325974222884,
      "learning_rate": 4.377637049265656e-05,
      "loss": 0.2079,
      "step": 2500
    },
    {
      "epoch": 1.7651195499296763,
      "grad_norm": 0.5436851111497996,
      "learning_rate": 4.337059739654683e-05,
      "loss": 0.2183,
      "step": 2510
    },
    {
      "epoch": 1.7721518987341773,
      "grad_norm": 0.47421926150725147,
      "learning_rate": 4.296526825190067e-05,
      "loss": 0.2117,
      "step": 2520
    },
    {
      "epoch": 1.7791842475386779,
      "grad_norm": 0.42380597078595433,
      "learning_rate": 4.256041020241074e-05,
      "loss": 0.2018,
      "step": 2530
    },
    {
      "epoch": 1.7862165963431786,
      "grad_norm": 0.5405785352682189,
      "learning_rate": 4.215605036022185e-05,
      "loss": 0.2014,
      "step": 2540
    },
    {
      "epoch": 1.7932489451476794,
      "grad_norm": 0.4506925586038866,
      "learning_rate": 4.175221580411544e-05,
      "loss": 0.1971,
      "step": 2550
    },
    {
      "epoch": 1.80028129395218,
      "grad_norm": 0.5349704919411162,
      "learning_rate": 4.134893357769598e-05,
      "loss": 0.2036,
      "step": 2560
    },
    {
      "epoch": 1.8073136427566807,
      "grad_norm": 0.4691014965648265,
      "learning_rate": 4.0946230687580126e-05,
      "loss": 0.22,
      "step": 2570
    },
    {
      "epoch": 1.8143459915611815,
      "grad_norm": 0.5454283003534375,
      "learning_rate": 4.054413410158806e-05,
      "loss": 0.2038,
      "step": 2580
    },
    {
      "epoch": 1.821378340365682,
      "grad_norm": 0.4904628331237507,
      "learning_rate": 4.0142670746937616e-05,
      "loss": 0.215,
      "step": 2590
    },
    {
      "epoch": 1.8284106891701828,
      "grad_norm": 0.5145131215987946,
      "learning_rate": 3.974186750844096e-05,
      "loss": 0.2088,
      "step": 2600
    },
    {
      "epoch": 1.8354430379746836,
      "grad_norm": 0.5556881180847458,
      "learning_rate": 3.9341751226704224e-05,
      "loss": 0.2042,
      "step": 2610
    },
    {
      "epoch": 1.842475386779184,
      "grad_norm": 0.7383691242691792,
      "learning_rate": 3.894234869633015e-05,
      "loss": 0.2226,
      "step": 2620
    },
    {
      "epoch": 1.849507735583685,
      "grad_norm": 0.5076177423005012,
      "learning_rate": 3.854368666412359e-05,
      "loss": 0.2114,
      "step": 2630
    },
    {
      "epoch": 1.8565400843881856,
      "grad_norm": 0.5425835046161948,
      "learning_rate": 3.814579182730046e-05,
      "loss": 0.1901,
      "step": 2640
    },
    {
      "epoch": 1.8635724331926864,
      "grad_norm": 0.6223995450487539,
      "learning_rate": 3.7748690831699854e-05,
      "loss": 0.2062,
      "step": 2650
    },
    {
      "epoch": 1.8706047819971872,
      "grad_norm": 0.4816445250496199,
      "learning_rate": 3.735241026999968e-05,
      "loss": 0.2093,
      "step": 2660
    },
    {
      "epoch": 1.8776371308016877,
      "grad_norm": 0.6377517878508234,
      "learning_rate": 3.695697667993585e-05,
      "loss": 0.21,
      "step": 2670
    },
    {
      "epoch": 1.8846694796061885,
      "grad_norm": 0.529578228507149,
      "learning_rate": 3.6562416542525014e-05,
      "loss": 0.2064,
      "step": 2680
    },
    {
      "epoch": 1.8917018284106892,
      "grad_norm": 0.5525393196264144,
      "learning_rate": 3.6168756280291386e-05,
      "loss": 0.193,
      "step": 2690
    },
    {
      "epoch": 1.8987341772151898,
      "grad_norm": 0.5404412690771467,
      "learning_rate": 3.5776022255497125e-05,
      "loss": 0.2032,
      "step": 2700
    },
    {
      "epoch": 1.9057665260196905,
      "grad_norm": 0.5825399134818101,
      "learning_rate": 3.538424076837702e-05,
      "loss": 0.1934,
      "step": 2710
    },
    {
      "epoch": 1.9127988748241913,
      "grad_norm": 0.633224898711067,
      "learning_rate": 3.4993438055377286e-05,
      "loss": 0.2157,
      "step": 2720
    },
    {
      "epoch": 1.9198312236286919,
      "grad_norm": 0.5321096529503401,
      "learning_rate": 3.4603640287398446e-05,
      "loss": 0.197,
      "step": 2730
    },
    {
      "epoch": 1.9268635724331928,
      "grad_norm": 0.4566615890070152,
      "learning_rate": 3.421487356804293e-05,
      "loss": 0.1903,
      "step": 2740
    },
    {
      "epoch": 1.9338959212376934,
      "grad_norm": 0.4963493939778582,
      "learning_rate": 3.38271639318668e-05,
      "loss": 0.2072,
      "step": 2750
    },
    {
      "epoch": 1.9409282700421941,
      "grad_norm": 0.4573220320482067,
      "learning_rate": 3.344053734263648e-05,
      "loss": 0.1891,
      "step": 2760
    },
    {
      "epoch": 1.947960618846695,
      "grad_norm": 0.5521515539830226,
      "learning_rate": 3.305501969158987e-05,
      "loss": 0.2056,
      "step": 2770
    },
    {
      "epoch": 1.9549929676511955,
      "grad_norm": 0.4721056961122773,
      "learning_rate": 3.267063679570259e-05,
      "loss": 0.1935,
      "step": 2780
    },
    {
      "epoch": 1.9620253164556962,
      "grad_norm": 0.5102461629871164,
      "learning_rate": 3.2287414395959094e-05,
      "loss": 0.2015,
      "step": 2790
    },
    {
      "epoch": 1.969057665260197,
      "grad_norm": 0.547570606015442,
      "learning_rate": 3.1905378155628766e-05,
      "loss": 0.2089,
      "step": 2800
    },
    {
      "epoch": 1.9760900140646975,
      "grad_norm": 0.5395738053345273,
      "learning_rate": 3.152455365854753e-05,
      "loss": 0.2073,
      "step": 2810
    },
    {
      "epoch": 1.9831223628691983,
      "grad_norm": 0.5601304980482977,
      "learning_rate": 3.114496640740434e-05,
      "loss": 0.2161,
      "step": 2820
    },
    {
      "epoch": 1.990154711673699,
      "grad_norm": 0.5962396964253005,
      "learning_rate": 3.0766641822033485e-05,
      "loss": 0.2175,
      "step": 2830
    },
    {
      "epoch": 1.9971870604781996,
      "grad_norm": 0.42522672676220774,
      "learning_rate": 3.0389605237712314e-05,
      "loss": 0.2076,
      "step": 2840
    },
    {
      "epoch": 2.0042194092827006,
      "grad_norm": 0.43582377428044117,
      "learning_rate": 3.0013881903464504e-05,
      "loss": 0.1832,
      "step": 2850
    },
    {
      "epoch": 2.011251758087201,
      "grad_norm": 0.649772850508386,
      "learning_rate": 2.9639496980369285e-05,
      "loss": 0.1892,
      "step": 2860
    },
    {
      "epoch": 2.0182841068917017,
      "grad_norm": 0.5375290692281995,
      "learning_rate": 2.926647553987645e-05,
      "loss": 0.174,
      "step": 2870
    },
    {
      "epoch": 2.0253164556962027,
      "grad_norm": 0.5730896646575641,
      "learning_rate": 2.889484256212739e-05,
      "loss": 0.1809,
      "step": 2880
    },
    {
      "epoch": 2.032348804500703,
      "grad_norm": 0.5559730399778622,
      "learning_rate": 2.8524622934282275e-05,
      "loss": 0.1728,
      "step": 2890
    },
    {
      "epoch": 2.0393811533052038,
      "grad_norm": 0.5865356261089262,
      "learning_rate": 2.8155841448853392e-05,
      "loss": 0.1829,
      "step": 2900
    },
    {
      "epoch": 2.0464135021097047,
      "grad_norm": 0.696283956395633,
      "learning_rate": 2.7788522802044947e-05,
      "loss": 0.1695,
      "step": 2910
    },
    {
      "epoch": 2.0534458509142053,
      "grad_norm": 0.496678572500719,
      "learning_rate": 2.7422691592099083e-05,
      "loss": 0.1764,
      "step": 2920
    },
    {
      "epoch": 2.0604781997187063,
      "grad_norm": 0.4978794670138377,
      "learning_rate": 2.70583723176488e-05,
      "loss": 0.1767,
      "step": 2930
    },
    {
      "epoch": 2.067510548523207,
      "grad_norm": 0.4420008995760854,
      "learning_rate": 2.669558937607718e-05,
      "loss": 0.1771,
      "step": 2940
    },
    {
      "epoch": 2.0745428973277074,
      "grad_norm": 0.5259704212150764,
      "learning_rate": 2.6334367061883647e-05,
      "loss": 0.1656,
      "step": 2950
    },
    {
      "epoch": 2.0815752461322083,
      "grad_norm": 0.5691255518286655,
      "learning_rate": 2.597472956505709e-05,
      "loss": 0.1701,
      "step": 2960
    },
    {
      "epoch": 2.088607594936709,
      "grad_norm": 0.5821410332542629,
      "learning_rate": 2.5616700969455786e-05,
      "loss": 0.1835,
      "step": 2970
    },
    {
      "epoch": 2.0956399437412094,
      "grad_norm": 0.47920026459471254,
      "learning_rate": 2.526030525119475e-05,
      "loss": 0.1735,
      "step": 2980
    },
    {
      "epoch": 2.1026722925457104,
      "grad_norm": 0.5612947423071523,
      "learning_rate": 2.4905566277039972e-05,
      "loss": 0.1694,
      "step": 2990
    },
    {
      "epoch": 2.109704641350211,
      "grad_norm": 0.6436232255400129,
      "learning_rate": 2.45525078028102e-05,
      "loss": 0.1741,
      "step": 3000
    },
    {
      "epoch": 2.1167369901547115,
      "grad_norm": 0.527858730055215,
      "learning_rate": 2.420115347178612e-05,
      "loss": 0.1662,
      "step": 3010
    },
    {
      "epoch": 2.1237693389592125,
      "grad_norm": 0.4882035702412138,
      "learning_rate": 2.3851526813126955e-05,
      "loss": 0.1861,
      "step": 3020
    },
    {
      "epoch": 2.130801687763713,
      "grad_norm": 0.5331287653248717,
      "learning_rate": 2.3503651240294834e-05,
      "loss": 0.1857,
      "step": 3030
    },
    {
      "epoch": 2.1378340365682136,
      "grad_norm": 0.5816027618960815,
      "learning_rate": 2.3157550049486853e-05,
      "loss": 0.1654,
      "step": 3040
    },
    {
      "epoch": 2.1448663853727146,
      "grad_norm": 0.47036384404787107,
      "learning_rate": 2.281324641807498e-05,
      "loss": 0.1703,
      "step": 3050
    },
    {
      "epoch": 2.151898734177215,
      "grad_norm": 0.5658711138099266,
      "learning_rate": 2.2470763403054008e-05,
      "loss": 0.1836,
      "step": 3060
    },
    {
      "epoch": 2.158931082981716,
      "grad_norm": 0.6248377112771585,
      "learning_rate": 2.213012393949737e-05,
      "loss": 0.1689,
      "step": 3070
    },
    {
      "epoch": 2.1659634317862166,
      "grad_norm": 0.5884439290730082,
      "learning_rate": 2.1791350839021384e-05,
      "loss": 0.1821,
      "step": 3080
    },
    {
      "epoch": 2.172995780590717,
      "grad_norm": 0.6546491586880211,
      "learning_rate": 2.145446678825751e-05,
      "loss": 0.1714,
      "step": 3090
    },
    {
      "epoch": 2.180028129395218,
      "grad_norm": 0.4775498071229501,
      "learning_rate": 2.111949434733314e-05,
      "loss": 0.1865,
      "step": 3100
    },
    {
      "epoch": 2.1870604781997187,
      "grad_norm": 0.54699822927024,
      "learning_rate": 2.0786455948360868e-05,
      "loss": 0.1805,
      "step": 3110
    },
    {
      "epoch": 2.1940928270042193,
      "grad_norm": 0.6121604616685885,
      "learning_rate": 2.0455373893936147e-05,
      "loss": 0.1801,
      "step": 3120
    },
    {
      "epoch": 2.2011251758087202,
      "grad_norm": 0.5863575953758159,
      "learning_rate": 2.0126270355643915e-05,
      "loss": 0.1743,
      "step": 3130
    },
    {
      "epoch": 2.208157524613221,
      "grad_norm": 0.47657536177524157,
      "learning_rate": 1.9799167372573657e-05,
      "loss": 0.1625,
      "step": 3140
    },
    {
      "epoch": 2.2151898734177213,
      "grad_norm": 0.6925025415854084,
      "learning_rate": 1.9474086849843676e-05,
      "loss": 0.1695,
      "step": 3150
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 0.5530190781244037,
      "learning_rate": 1.9151050557134037e-05,
      "loss": 0.1843,
      "step": 3160
    },
    {
      "epoch": 2.229254571026723,
      "grad_norm": 0.5208445604922987,
      "learning_rate": 1.8830080127228794e-05,
      "loss": 0.1672,
      "step": 3170
    },
    {
      "epoch": 2.2362869198312234,
      "grad_norm": 0.5803453310910887,
      "learning_rate": 1.851119705456729e-05,
      "loss": 0.1848,
      "step": 3180
    },
    {
      "epoch": 2.2433192686357244,
      "grad_norm": 0.7117181751838532,
      "learning_rate": 1.8194422693804714e-05,
      "loss": 0.1876,
      "step": 3190
    },
    {
      "epoch": 2.250351617440225,
      "grad_norm": 0.6407207151584157,
      "learning_rate": 1.7879778258382103e-05,
      "loss": 0.1673,
      "step": 3200
    },
    {
      "epoch": 2.257383966244726,
      "grad_norm": 0.5546479999775682,
      "learning_rate": 1.756728481910566e-05,
      "loss": 0.1778,
      "step": 3210
    },
    {
      "epoch": 2.2644163150492265,
      "grad_norm": 0.5979681098991513,
      "learning_rate": 1.725696330273575e-05,
      "loss": 0.1788,
      "step": 3220
    },
    {
      "epoch": 2.271448663853727,
      "grad_norm": 0.4881780781680201,
      "learning_rate": 1.694883449058553e-05,
      "loss": 0.1778,
      "step": 3230
    },
    {
      "epoch": 2.278481012658228,
      "grad_norm": 0.6502229143723968,
      "learning_rate": 1.664291901712919e-05,
      "loss": 0.1752,
      "step": 3240
    },
    {
      "epoch": 2.2855133614627285,
      "grad_norm": 0.606160925483686,
      "learning_rate": 1.633923736862024e-05,
      "loss": 0.1824,
      "step": 3250
    },
    {
      "epoch": 2.292545710267229,
      "grad_norm": 0.6398702074440865,
      "learning_rate": 1.6037809881719508e-05,
      "loss": 0.1823,
      "step": 3260
    },
    {
      "epoch": 2.29957805907173,
      "grad_norm": 0.5870312626449913,
      "learning_rate": 1.573865674213328e-05,
      "loss": 0.1901,
      "step": 3270
    },
    {
      "epoch": 2.3066104078762306,
      "grad_norm": 0.5991410788777022,
      "learning_rate": 1.5441797983261592e-05,
      "loss": 0.1806,
      "step": 3280
    },
    {
      "epoch": 2.313642756680731,
      "grad_norm": 0.5544952285412222,
      "learning_rate": 1.5147253484856538e-05,
      "loss": 0.1749,
      "step": 3290
    },
    {
      "epoch": 2.320675105485232,
      "grad_norm": 0.517100842143163,
      "learning_rate": 1.4855042971691102e-05,
      "loss": 0.1699,
      "step": 3300
    },
    {
      "epoch": 2.3277074542897327,
      "grad_norm": 0.528364236483548,
      "learning_rate": 1.4565186012238124e-05,
      "loss": 0.1788,
      "step": 3310
    },
    {
      "epoch": 2.3347398030942337,
      "grad_norm": 0.5946681525325208,
      "learning_rate": 1.4277702017359967e-05,
      "loss": 0.1667,
      "step": 3320
    },
    {
      "epoch": 2.3417721518987342,
      "grad_norm": 0.6295218601387751,
      "learning_rate": 1.3992610239008552e-05,
      "loss": 0.1755,
      "step": 3330
    },
    {
      "epoch": 2.3488045007032348,
      "grad_norm": 0.6188628402309146,
      "learning_rate": 1.3709929768936142e-05,
      "loss": 0.1803,
      "step": 3340
    },
    {
      "epoch": 2.3558368495077358,
      "grad_norm": 0.5691259978902261,
      "learning_rate": 1.3429679537416867e-05,
      "loss": 0.1715,
      "step": 3350
    },
    {
      "epoch": 2.3628691983122363,
      "grad_norm": 0.6122160069406407,
      "learning_rate": 1.3151878311978921e-05,
      "loss": 0.1802,
      "step": 3360
    },
    {
      "epoch": 2.369901547116737,
      "grad_norm": 0.5261836444771291,
      "learning_rate": 1.2876544696147863e-05,
      "loss": 0.1835,
      "step": 3370
    },
    {
      "epoch": 2.376933895921238,
      "grad_norm": 0.5269042581895772,
      "learning_rate": 1.2603697128200703e-05,
      "loss": 0.1805,
      "step": 3380
    },
    {
      "epoch": 2.3839662447257384,
      "grad_norm": 0.6311408047704535,
      "learning_rate": 1.2333353879931186e-05,
      "loss": 0.1649,
      "step": 3390
    },
    {
      "epoch": 2.390998593530239,
      "grad_norm": 0.5809554272710555,
      "learning_rate": 1.2065533055426231e-05,
      "loss": 0.1613,
      "step": 3400
    },
    {
      "epoch": 2.39803094233474,
      "grad_norm": 0.6156206816107349,
      "learning_rate": 1.180025258985344e-05,
      "loss": 0.1826,
      "step": 3410
    },
    {
      "epoch": 2.4050632911392404,
      "grad_norm": 0.527685113240809,
      "learning_rate": 1.1537530248260154e-05,
      "loss": 0.165,
      "step": 3420
    },
    {
      "epoch": 2.4120956399437414,
      "grad_norm": 0.6228824946529312,
      "learning_rate": 1.1277383624383691e-05,
      "loss": 0.1856,
      "step": 3430
    },
    {
      "epoch": 2.419127988748242,
      "grad_norm": 0.5570571584478242,
      "learning_rate": 1.1019830139473182e-05,
      "loss": 0.1888,
      "step": 3440
    },
    {
      "epoch": 2.4261603375527425,
      "grad_norm": 0.6220877725520418,
      "learning_rate": 1.0764887041122945e-05,
      "loss": 0.1756,
      "step": 3450
    },
    {
      "epoch": 2.4331926863572435,
      "grad_norm": 0.5845601798355293,
      "learning_rate": 1.0512571402117422e-05,
      "loss": 0.1659,
      "step": 3460
    },
    {
      "epoch": 2.440225035161744,
      "grad_norm": 0.5572824014980456,
      "learning_rate": 1.0262900119287877e-05,
      "loss": 0.1732,
      "step": 3470
    },
    {
      "epoch": 2.4472573839662446,
      "grad_norm": 0.6679599685587864,
      "learning_rate": 1.0015889912380877e-05,
      "loss": 0.1891,
      "step": 3480
    },
    {
      "epoch": 2.4542897327707456,
      "grad_norm": 0.5994892837876911,
      "learning_rate": 9.771557322938601e-06,
      "loss": 0.1864,
      "step": 3490
    },
    {
      "epoch": 2.461322081575246,
      "grad_norm": 0.6218713459302284,
      "learning_rate": 9.52991871319115e-06,
      "loss": 0.1737,
      "step": 3500
    },
    {
      "epoch": 2.4683544303797467,
      "grad_norm": 0.5571777407228704,
      "learning_rate": 9.290990264960731e-06,
      "loss": 0.1746,
      "step": 3510
    },
    {
      "epoch": 2.4753867791842477,
      "grad_norm": 0.5597793162950108,
      "learning_rate": 9.05478797857811e-06,
      "loss": 0.173,
      "step": 3520
    },
    {
      "epoch": 2.482419127988748,
      "grad_norm": 0.4893509947385561,
      "learning_rate": 8.821327671811025e-06,
      "loss": 0.168,
      "step": 3530
    },
    {
      "epoch": 2.489451476793249,
      "grad_norm": 0.5075721776821063,
      "learning_rate": 8.590624978804995e-06,
      "loss": 0.1683,
      "step": 3540
    },
    {
      "epoch": 2.4964838255977497,
      "grad_norm": 0.6280485888679073,
      "learning_rate": 8.36269534903627e-06,
      "loss": 0.1706,
      "step": 3550
    },
    {
      "epoch": 2.5035161744022503,
      "grad_norm": 0.5036166482761637,
      "learning_rate": 8.13755404627728e-06,
      "loss": 0.1737,
      "step": 3560
    },
    {
      "epoch": 2.510548523206751,
      "grad_norm": 0.5496024097129071,
      "learning_rate": 7.915216147574478e-06,
      "loss": 0.1841,
      "step": 3570
    },
    {
      "epoch": 2.517580872011252,
      "grad_norm": 0.5506335325827891,
      "learning_rate": 7.695696542238611e-06,
      "loss": 0.1786,
      "step": 3580
    },
    {
      "epoch": 2.5246132208157523,
      "grad_norm": 0.6173456676346087,
      "learning_rate": 7.479009930847691e-06,
      "loss": 0.1749,
      "step": 3590
    },
    {
      "epoch": 2.5316455696202533,
      "grad_norm": 0.6119327799330374,
      "learning_rate": 7.265170824262485e-06,
      "loss": 0.1762,
      "step": 3600
    },
    {
      "epoch": 2.538677918424754,
      "grad_norm": 0.5334834403660988,
      "learning_rate": 7.054193542654813e-06,
      "loss": 0.1812,
      "step": 3610
    },
    {
      "epoch": 2.5457102672292544,
      "grad_norm": 0.5393554287734972,
      "learning_rate": 6.846092214548561e-06,
      "loss": 0.174,
      "step": 3620
    },
    {
      "epoch": 2.5527426160337554,
      "grad_norm": 0.6892471139938006,
      "learning_rate": 6.640880775873492e-06,
      "loss": 0.173,
      "step": 3630
    },
    {
      "epoch": 2.559774964838256,
      "grad_norm": 0.5588215685305369,
      "learning_rate": 6.438572969032075e-06,
      "loss": 0.1789,
      "step": 3640
    },
    {
      "epoch": 2.566807313642757,
      "grad_norm": 0.5927323536714805,
      "learning_rate": 6.239182341979105e-06,
      "loss": 0.1707,
      "step": 3650
    },
    {
      "epoch": 2.5738396624472575,
      "grad_norm": 0.5417213035179007,
      "learning_rate": 6.042722247314508e-06,
      "loss": 0.1655,
      "step": 3660
    },
    {
      "epoch": 2.580872011251758,
      "grad_norm": 0.6593863416055188,
      "learning_rate": 5.849205841389144e-06,
      "loss": 0.175,
      "step": 3670
    },
    {
      "epoch": 2.5879043600562586,
      "grad_norm": 0.5627914307538587,
      "learning_rate": 5.658646083423724e-06,
      "loss": 0.1759,
      "step": 3680
    },
    {
      "epoch": 2.5949367088607596,
      "grad_norm": 0.5298509017100362,
      "learning_rate": 5.471055734641034e-06,
      "loss": 0.1747,
      "step": 3690
    },
    {
      "epoch": 2.60196905766526,
      "grad_norm": 0.5594667241519263,
      "learning_rate": 5.286447357411278e-06,
      "loss": 0.1813,
      "step": 3700
    },
    {
      "epoch": 2.609001406469761,
      "grad_norm": 0.5802705494686691,
      "learning_rate": 5.104833314410901e-06,
      "loss": 0.1719,
      "step": 3710
    },
    {
      "epoch": 2.6160337552742616,
      "grad_norm": 0.7497204281064991,
      "learning_rate": 4.926225767794612e-06,
      "loss": 0.1821,
      "step": 3720
    },
    {
      "epoch": 2.623066104078762,
      "grad_norm": 0.5744748738196108,
      "learning_rate": 4.750636678380982e-06,
      "loss": 0.1743,
      "step": 3730
    },
    {
      "epoch": 2.630098452883263,
      "grad_norm": 0.5552522478713581,
      "learning_rate": 4.578077804851422e-06,
      "loss": 0.1739,
      "step": 3740
    },
    {
      "epoch": 2.6371308016877637,
      "grad_norm": 0.6332654945679855,
      "learning_rate": 4.408560702962772e-06,
      "loss": 0.1678,
      "step": 3750
    },
    {
      "epoch": 2.6441631504922647,
      "grad_norm": 0.5236902716586854,
      "learning_rate": 4.242096724773431e-06,
      "loss": 0.1753,
      "step": 3760
    },
    {
      "epoch": 2.6511954992967652,
      "grad_norm": 0.5569120894391199,
      "learning_rate": 4.078697017883138e-06,
      "loss": 0.1753,
      "step": 3770
    },
    {
      "epoch": 2.6582278481012658,
      "grad_norm": 0.6219964673238381,
      "learning_rate": 3.918372524686448e-06,
      "loss": 0.1855,
      "step": 3780
    },
    {
      "epoch": 2.6652601969057663,
      "grad_norm": 0.6139559566814781,
      "learning_rate": 3.7611339816399916e-06,
      "loss": 0.1726,
      "step": 3790
    },
    {
      "epoch": 2.6722925457102673,
      "grad_norm": 0.612229718268664,
      "learning_rate": 3.606991918543412e-06,
      "loss": 0.1834,
      "step": 3800
    },
    {
      "epoch": 2.679324894514768,
      "grad_norm": 0.6690195193410534,
      "learning_rate": 3.4559566578342917e-06,
      "loss": 0.1766,
      "step": 3810
    },
    {
      "epoch": 2.686357243319269,
      "grad_norm": 0.506489102115052,
      "learning_rate": 3.308038313896844e-06,
      "loss": 0.1575,
      "step": 3820
    },
    {
      "epoch": 2.6933895921237694,
      "grad_norm": 0.5443733100688434,
      "learning_rate": 3.1632467923845834e-06,
      "loss": 0.1793,
      "step": 3830
    },
    {
      "epoch": 2.70042194092827,
      "grad_norm": 0.5659363195283773,
      "learning_rate": 3.0215917895570154e-06,
      "loss": 0.1706,
      "step": 3840
    },
    {
      "epoch": 2.7074542897327705,
      "grad_norm": 0.5323195524790808,
      "learning_rate": 2.883082791630243e-06,
      "loss": 0.1692,
      "step": 3850
    },
    {
      "epoch": 2.7144866385372715,
      "grad_norm": 0.6474001391441042,
      "learning_rate": 2.747729074141753e-06,
      "loss": 0.1813,
      "step": 3860
    },
    {
      "epoch": 2.721518987341772,
      "grad_norm": 0.6131937654858043,
      "learning_rate": 2.6155397013292448e-06,
      "loss": 0.1749,
      "step": 3870
    },
    {
      "epoch": 2.728551336146273,
      "grad_norm": 0.5651668200516435,
      "learning_rate": 2.486523525523621e-06,
      "loss": 0.1736,
      "step": 3880
    },
    {
      "epoch": 2.7355836849507735,
      "grad_norm": 0.545787383062354,
      "learning_rate": 2.360689186556164e-06,
      "loss": 0.1783,
      "step": 3890
    },
    {
      "epoch": 2.742616033755274,
      "grad_norm": 0.7353798655876767,
      "learning_rate": 2.2380451111799816e-06,
      "loss": 0.186,
      "step": 3900
    },
    {
      "epoch": 2.749648382559775,
      "grad_norm": 0.5438725856262935,
      "learning_rate": 2.11859951250567e-06,
      "loss": 0.1766,
      "step": 3910
    },
    {
      "epoch": 2.7566807313642756,
      "grad_norm": 0.6792616175030478,
      "learning_rate": 2.002360389451302e-06,
      "loss": 0.1758,
      "step": 3920
    },
    {
      "epoch": 2.7637130801687766,
      "grad_norm": 0.5665839114289506,
      "learning_rate": 1.8893355262067925e-06,
      "loss": 0.1714,
      "step": 3930
    },
    {
      "epoch": 2.770745428973277,
      "grad_norm": 0.6323749847333218,
      "learning_rate": 1.779532491712571e-06,
      "loss": 0.1869,
      "step": 3940
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 0.6319620341452806,
      "learning_rate": 1.672958639152744e-06,
      "loss": 0.1728,
      "step": 3950
    },
    {
      "epoch": 2.7848101265822782,
      "grad_norm": 0.7097381491031827,
      "learning_rate": 1.5696211054626708e-06,
      "loss": 0.1699,
      "step": 3960
    },
    {
      "epoch": 2.791842475386779,
      "grad_norm": 0.60874820915116,
      "learning_rate": 1.4695268108510074e-06,
      "loss": 0.1694,
      "step": 3970
    },
    {
      "epoch": 2.7988748241912798,
      "grad_norm": 0.5877816523805208,
      "learning_rate": 1.3726824583363107e-06,
      "loss": 0.1675,
      "step": 3980
    },
    {
      "epoch": 2.8059071729957807,
      "grad_norm": 0.6144238250585669,
      "learning_rate": 1.2790945332981142e-06,
      "loss": 0.1781,
      "step": 3990
    },
    {
      "epoch": 2.8129395218002813,
      "grad_norm": 0.602897557332646,
      "learning_rate": 1.1887693030426529e-06,
      "loss": 0.1882,
      "step": 4000
    },
    {
      "epoch": 2.819971870604782,
      "grad_norm": 0.5300206723351903,
      "learning_rate": 1.1017128163831658e-06,
      "loss": 0.1628,
      "step": 4010
    },
    {
      "epoch": 2.827004219409283,
      "grad_norm": 0.5654312777293645,
      "learning_rate": 1.0179309032347929e-06,
      "loss": 0.1776,
      "step": 4020
    },
    {
      "epoch": 2.8340365682137834,
      "grad_norm": 0.5992910134069783,
      "learning_rate": 9.374291742241914e-07,
      "loss": 0.1661,
      "step": 4030
    },
    {
      "epoch": 2.8410689170182843,
      "grad_norm": 0.5897281343573126,
      "learning_rate": 8.602130203138048e-07,
      "loss": 0.1809,
      "step": 4040
    },
    {
      "epoch": 2.848101265822785,
      "grad_norm": 0.6118171911478647,
      "learning_rate": 7.862876124408225e-07,
      "loss": 0.1646,
      "step": 4050
    },
    {
      "epoch": 2.8551336146272854,
      "grad_norm": 0.6713218769513286,
      "learning_rate": 7.156579011709352e-07,
      "loss": 0.1741,
      "step": 4060
    },
    {
      "epoch": 2.862165963431786,
      "grad_norm": 0.6430780533080189,
      "learning_rate": 6.483286163667723e-07,
      "loss": 0.1758,
      "step": 4070
    },
    {
      "epoch": 2.869198312236287,
      "grad_norm": 0.6136324090235825,
      "learning_rate": 5.843042668711995e-07,
      "loss": 0.1616,
      "step": 4080
    },
    {
      "epoch": 2.8762306610407875,
      "grad_norm": 0.5447822006735529,
      "learning_rate": 5.235891402053162e-07,
      "loss": 0.1668,
      "step": 4090
    },
    {
      "epoch": 2.8832630098452885,
      "grad_norm": 0.5714755718460917,
      "learning_rate": 4.661873022813956e-07,
      "loss": 0.172,
      "step": 4100
    },
    {
      "epoch": 2.890295358649789,
      "grad_norm": 0.5276889460172098,
      "learning_rate": 4.121025971305592e-07,
      "loss": 0.1737,
      "step": 4110
    },
    {
      "epoch": 2.8973277074542896,
      "grad_norm": 0.6594555540459601,
      "learning_rate": 3.613386466453761e-07,
      "loss": 0.1732,
      "step": 4120
    },
    {
      "epoch": 2.9043600562587906,
      "grad_norm": 0.49740022376019266,
      "learning_rate": 3.138988503373075e-07,
      "loss": 0.1725,
      "step": 4130
    },
    {
      "epoch": 2.911392405063291,
      "grad_norm": 0.7002552123892382,
      "learning_rate": 2.697863851090443e-07,
      "loss": 0.1715,
      "step": 4140
    },
    {
      "epoch": 2.918424753867792,
      "grad_norm": 0.5923960870169006,
      "learning_rate": 2.2900420504177734e-07,
      "loss": 0.1907,
      "step": 4150
    },
    {
      "epoch": 2.9254571026722926,
      "grad_norm": 0.5322319170102053,
      "learning_rate": 1.9155504119734434e-07,
      "loss": 0.1643,
      "step": 4160
    },
    {
      "epoch": 2.932489451476793,
      "grad_norm": 0.6425799740893986,
      "learning_rate": 1.5744140143537646e-07,
      "loss": 0.1834,
      "step": 4170
    },
    {
      "epoch": 2.9395218002812937,
      "grad_norm": 0.5792063083398251,
      "learning_rate": 1.2666557024531568e-07,
      "loss": 0.1811,
      "step": 4180
    },
    {
      "epoch": 2.9465541490857947,
      "grad_norm": 0.536660971055042,
      "learning_rate": 9.922960859345409e-08,
      "loss": 0.1547,
      "step": 4190
    },
    {
      "epoch": 2.9535864978902953,
      "grad_norm": 0.6096333137661514,
      "learning_rate": 7.513535378491644e-08,
      "loss": 0.1651,
      "step": 4200
    },
    {
      "epoch": 2.9606188466947962,
      "grad_norm": 0.5290950076534895,
      "learning_rate": 5.4384419340597345e-08,
      "loss": 0.1639,
      "step": 4210
    },
    {
      "epoch": 2.967651195499297,
      "grad_norm": 0.5804389553770049,
      "learning_rate": 3.6978194889142334e-08,
      "loss": 0.174,
      "step": 4220
    },
    {
      "epoch": 2.9746835443037973,
      "grad_norm": 0.5672387477145835,
      "learning_rate": 2.291784607386105e-08,
      "loss": 0.1907,
      "step": 4230
    },
    {
      "epoch": 2.9817158931082983,
      "grad_norm": 0.5673233879173774,
      "learning_rate": 1.2204314474684176e-08,
      "loss": 0.171,
      "step": 4240
    },
    {
      "epoch": 2.988748241912799,
      "grad_norm": 0.5710485774923931,
      "learning_rate": 4.838317545102778e-09,
      "loss": 0.1729,
      "step": 4250
    },
    {
      "epoch": 2.9957805907173,
      "grad_norm": 0.5872806772885631,
      "learning_rate": 8.203485641233855e-10,
      "loss": 0.1861,
      "step": 4260
    },
    {
      "epoch": 3.0,
      "step": 4266,
      "total_flos": 1006628057907200.0,
      "train_loss": 0.23823351388909814,
      "train_runtime": 39865.5857,
      "train_samples_per_second": 0.856,
      "train_steps_per_second": 0.107
    }
  ],
  "logging_steps": 10,
  "max_steps": 4266,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1006628057907200.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
